# ================================
# RDBMS CONFIG
# ================================

# PostgreSQL конфигурация
POSTGRESQL_ROOT_PASSWORD=root
# Пароль для пользователя root в PostgreSQL. Используется для административных задач.

POSTGRESQL_APP_HOST=postgresql
# Хост, на котором запущен PostgreSQL сервер. Обычно это имя сервиса в Docker или IP адрес.

POSTGRESQL_APP_DB=postgres_db
# Название базы данных для приложения в PostgreSQL.

POSTGRESQL_APP_SCHEMA=source
# Схема в PostgreSQL, которая будет использоваться приложением. Схемы помогают организовать объекты базы данных.

POSTGRESQL_APP_USER=root
# Имя пользователя, под которым приложение будет подключаться к PostgreSQL.

POSTGRESQL_APP_PASSWORD=root
# Пароль для пользователя приложения в PostgreSQL.

# MySQL конфигурация
MYSQL_ROOT_PASSWORD=root
# Пароль для пользователя root в MySQL. Используется для административных задач.

MYSQL_APP_HOST=mysql
# Хост, на котором запущен MySQL сервер. Обычно это имя сервиса в Docker или IP адрес.

MYSQL_APP_DB=mysql_db
# Название базы данных для приложения в MySQL.

MYSQL_APP_USER=root
# Имя пользователя, под которым приложение будет подключаться к MySQL.

MYSQL_APP_PASSWORD=root
# Пароль для пользователя приложения в MySQL.

# ================================
# MESSAGING CONFIG
# ================================

# Kafka конфигурация
KAFKA_BROKER_ID=1
# Уникальный идентификатор брокера Kafka в кластере.

KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
# Адрес и порт подключения к Zookeeper, который управляет кластером Kafka.

KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
# Карта протоколов безопасности для различных слушателей Kafka. В данном случае используется PLAINTEXT без шифрования.

KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
# Адреса и порты, на которых Kafka будет объявлять себя для других сервисов и внешних клиентов.

KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
# Фактор репликации для темы offset'ов Kafka. Обычно устанавливается равным количеству брокеров для отказоустойчивости.

KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
# Задержка перед началом ребалансировки групп потребителей Kafka.

KAFKA_INTERNAL_CONNECT_PATH=kafka:29092
# Внутренний путь подключения к Kafka, используемый внутри сети.

KAFKA_TOPIC_NAME=new_user_events
# Имя темы Kafka, которая будет использоваться для передачи событий о новых пользователях.

# ================================
# DATAGEN CONFIG
# ================================

# Конфигурация генерации данных
PG_DATAGEN_NUM_USERS=500
# Количество пользователей, которые будут сгенерированы для PostgreSQL.

PG_DATAGEN_NUM_PRODUCTS=800
# Количество продуктов, которые будут сгенерированы для PostgreSQL.

PG_DATAGEN_NUM_ORDERS=3000
# Количество заказов, которые будут сгенерированы для PostgreSQL.

PG_DATAGEN_NUM_ORDER_DETAILS_MIN=1
# Минимальное количество деталей заказа, генерируемых для каждого заказа.

PG_DATAGEN_NUM_ORDER_DETAILS_MAX=10
# Максимальное количество деталей заказа, генерируемых для каждого заказа.

PG_DATAGEN_NUM_REVIEWS=2000
# Количество отзывов, которые будут сгенерированы для PostgreSQL.

PG_DATAGEN_NUM_LOYALTY_POINTS=3000
# Количество бонусных баллов лояльности, которые будут сгенерированы для PostgreSQL.

KAFKA_DATAGEN_PERIOD_SECS=5
# Период генерации данных для Kafka в секундах. Определяет, как часто будут отправляться новые события.

# ================================
# AIRFLOW CONFIG
# ================================

# Конфигурация Apache Airflow
AIRFLOW__CORE__EXECUTOR=LocalExecutor
# Тип исполнительного механизма Airflow. LocalExecutor запускает задачи параллельно на локальной машине.

AIRFLOW__CORE__LOAD_EXAMPLES=false
# Отключает загрузку примеров DAG'ов Airflow, что полезно для производственной среды.

AIRFLOW__CORE__DAG_CONCURRENCY=4
# Максимальное количество задач, которые могут выполняться одновременно для одного DAG.

AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgresql:5432/airflow_db
# Строка подключения к базе данных Airflow через SQL Alchemy. В данном случае используется PostgreSQL.

AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=true
# Включает проверку состояния планировщика Airflow для мониторинга его работы.

AIRFLOW__WEBSERVER__SECRET_KEY=UNSAFE!
# Секретный ключ для веб-сервера Airflow. Используется для безопасности сессий и других криптографических операций. Рекомендуется использовать сложный и уникальный ключ.

_AIRFLOW_WWW_USER_USERNAME=airflow
# Имя пользователя для доступа к веб-интерфейсу Airflow.

_AIRFLOW_WWW_USER_PASSWORD=airflow
# Пароль для пользователя веб-интерфейса Airflow.

AIRFLOW_UID=50000
# UID пользователя Airflow в системе. Используется для соответствия пользователей между контейнерами и хостом.

# ================================
# SPARK CONFIG
# ================================

# Конфигурация Apache Spark
SPARK_RPC_AUTHENTICATION_ENABLED=no
# Отключает аутентификацию RPC в Spark.

SPARK_RPC_ENCRYPTION_ENABLED=no
# Отключает шифрование RPC сообщений в Spark.

SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
# Отключает шифрование локального хранилища Spark.

SPARK_SSL_ENABLED=no
# Отключает SSL в Spark для всех коммуникаций.

SPARK_MASTER_HOST=spark-master
# Хост, на котором запущен мастер узел Spark. Обычно это имя сервиса в Docker или IP адрес.

SPARK_MASTER_PORT=7077
# Порт, на котором мастер узел Spark слушает подключения. Стандартный порт для Spark Master.